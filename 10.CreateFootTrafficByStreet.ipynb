{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "124d28bb",
   "metadata": {},
   "source": [
    "# Create a Foot Traffic Data Set by street \n",
    "\n",
    "Based off the XPlore logic, this time load in more more foot traffic data based on the full history downloaded and saved to /data_files_raw/foot_traffic_melb/ folder\n",
    "\n",
    "This time, rather than aggregate all the street numbers to get a total melbourne number, cherry pick some of the streets. Convert it to a long format with the street name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a49d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "from utilities import data_basic_utility as databasic\n",
    "from utilities import regex_utility as reutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c761ff",
   "metadata": {},
   "source": [
    "# File Variables\n",
    "\n",
    "Set the start and end date of the time frame of data to load in and combine into one unified file\n",
    "\n",
    "This is the list of all Streets that exist in all files from Jan 2013 to July 2022\n",
    "['Date', 'Hour', 'Bourke Street Mall (North)', 'Bourke Street Mall (South)', 'Melbourne Central', 'Town Hall (West)', 'Princes Bridge', 'Birrarung Marr', 'Webb Bridge', 'Southern Cross Station', 'Victoria Point', 'Waterfront City', 'New Quay', 'Flagstaff Station', 'Sandridge Bridge', 'State Library', 'Collins Place (South)', 'Collins Place (North)', 'Chinatown-Swanston St (North)', 'Flinders St-Elizabeth St (East)', 'Spencer St-Collins St (South)', 'Spencer St-Collins St (North)', 'QV Market-Peel St']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555286f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "filesEndDate = datetime(2022, 7, 1)\n",
    "#filesStartDate = datetime(2022, 4, 1)\n",
    "filesStartDate = datetime(2013, 1, 1)\n",
    "\n",
    "footTrafficFolder = \"./data_files_raw/foot_traffic_melb/\"\n",
    "tempFolder = \"./tmp/\"\n",
    "\n",
    "#Create a list of streets to use. Try to get a good cross section of the city, but not too many locations\n",
    "streetsToUse = [ \n",
    "    \"Bourke Street Mall (North)\",\n",
    "    \"Melbourne Central\",\n",
    "    \"Southern Cross Station\",\n",
    "    \"Chinatown-Swanston St (North)\",\n",
    "    \"Spencer St-Collins St (North)\",\n",
    "    \"QV Market-Peel St\",\n",
    "    \"Collins Place (North)\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load all the weather data files like rain and temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd3003a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rain = pd.read_csv(\"IDCJAC0009_086338_1800_Data.csv\")\n",
    "max_temp = pd.read_csv(\"IDCJAC0010_086338_1800_Data.csv\")\n",
    "min_temp = pd.read_csv(\"IDCJAC0011_086338_1800_Data.csv\")\n",
    "solar_exp = pd.read_csv(\"IDCJAC0016_086338_1800_Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddeb2b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions for data files\n",
    "def make_date_col(df):\n",
    "    df[\"date\"] = df['Day'].astype(str) + \"/\" + df['Month'].astype(str) + \"/\" + df['Year'].astype(str)\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"], format=\"%d/%m/%Y\")\n",
    "    return df['date']\n",
    "\n",
    "    \n",
    "def filter_weathers(df, startDate='2022-07-01', endDate='2022-07-31'):\n",
    "    df = df.loc[(df['date'] >= startDate) & (df['date'] <= endDate)]\n",
    "    return df    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca571705",
   "metadata": {},
   "source": [
    "## Rain clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025abfb0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(rain.info())\n",
    "rain.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6539eb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rain = rain.drop(labels=['Product code', 'Bureau of Meteorology station number'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b95bdca",
   "metadata": {},
   "outputs": [],
   "source": [
    "rain[\"date\"] = make_date_col(rain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba682f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rain.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbef1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "rain.rename(columns={'Rainfall amount (millimetres)':\"total_rain\"},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ff4fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a940c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rain.sort_index(ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05688e6",
   "metadata": {},
   "source": [
    "## Foot traffic clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e76e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have a look at one of the files\n",
    "foot_traffic = pd.read_csv(\"July_2022.csv\")\n",
    "\n",
    "print(foot_traffic.info())\n",
    "foot_traffic.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a123d308",
   "metadata": {},
   "source": [
    "Example of the working to convert a file so that it has counted up all the numbers for a day, but only for the streets to use, and then also pivoted into a longer format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128f818b",
   "metadata": {},
   "outputs": [],
   "source": [
    "foot_traffic=foot_traffic.replace(to_replace=[\"na\",\"undefined\"],value=0)\n",
    "columnsToUse = [ \"Date\", \"Hour\" ]\n",
    "columnsToUse = columnsToUse + streetsToUse\n",
    "#print(columnsToUse)\n",
    "\n",
    "foot_traffic = foot_traffic[columnsToUse]\n",
    "foot_traffic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153cf1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFtStreet = pd.melt(foot_traffic, id_vars=[ \"Date\", \"Hour\" ], var_name=\"Street\")\n",
    "dfFtStreet = dfFtStreet.rename(columns = { \"value\":\"people\" })\n",
    "dfFtStreet[\"people\"] = dfFtStreet.apply(lambda x: int(x[\"people\"]), axis=1)\n",
    "print(dfFtStreet.info())\n",
    "dfFtStreet.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732d0240",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFtStreet = dfFtStreet.groupby([ \"Date\", \"Street\" ])[\"people\"].sum().reset_index()\n",
    "\n",
    "dfFtStreet.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ea8cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is basically Freddie's logic of loading in one month's file, cleaning it and converting it to a total people count\n",
    "def loadAndCountFootTrafficFile(dataFile):\n",
    "    foot_traffic = pd.read_csv(footTrafficFolder + dataFile)\n",
    "    foot_traffic=foot_traffic.replace(to_replace=[\"na\",\"undefined\"],value=0)\n",
    "    # foot_traffic[\"total_people\"] = foot_traffic.iloc[:,2:].sum(axis=1)\n",
    "\n",
    "    # get the first date to test the structure\n",
    "    firstDate = foot_traffic[\"Date\"][0]\n",
    "    if reutil.re_is_match(reutil.regex_DateDdMmYyyy(), firstDate):\n",
    "        foot_traffic[\"Date\"] = pd.to_datetime(foot_traffic[\"Date\"], format=\"%d/%m/%Y\")\n",
    "    elif reutil.re_is_match(reutil.regex_DateDdMmYy(), firstDate):\n",
    "        foot_traffic[\"Date\"] = pd.to_datetime(foot_traffic[\"Date\"], format=\"%d/%m/%y\")\n",
    "    elif reutil.re_is_match(reutil.regex_DateDdMmmYy(), firstDate):\n",
    "        foot_traffic[\"Date\"] = pd.to_datetime(foot_traffic[\"Date\"], format=\"%d-%b-%y\")    \n",
    "\n",
    "    # First, filter out the streets we don't want to use\n",
    "    columnsToUse = [ \"Date\", \"Hour\" ]\n",
    "    columnsToUse = columnsToUse + streetsToUse\n",
    "    foot_traffic = foot_traffic[columnsToUse]\n",
    "\n",
    "    # Then, unpivot the data by the date and hour, so we have records of Street name and total_people\n",
    "    foot_traffic = pd.melt(foot_traffic, id_vars=[ \"Date\", \"Hour\" ], var_name=\"street\")\n",
    "    foot_traffic = foot_traffic.rename(columns = { \"value\":\"total_people\" })\n",
    "    foot_traffic.loc[foot_traffic[\"total_people\"].isna(), \"total_people\"] = 0\n",
    "    foot_traffic[\"total_people\"] = foot_traffic.apply(lambda x: int(x[\"total_people\"]), axis=1)\n",
    "\n",
    "    # Then aggregate all the hourly numbers so we have a count by street and day\n",
    "    foot_traffic = foot_traffic.groupby([ \"Date\", \"street\" ])[\"total_people\"].sum().reset_index()\n",
    "    foot_traffic.rename(columns={'Date':'date'}, inplace=True)\n",
    "    return foot_traffic\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57eec026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the function\n",
    "dfFT_202207 = loadAndCountFootTrafficFile(\"July_2022.csv\")\n",
    "\n",
    "print(dfFT_202207.info())\n",
    "dfFT_202207.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b9b5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, start with the end month, load the data into a dataframe\n",
    "fileName = filesEndDate.strftime(\"%B\") + \"_\" + filesEndDate.strftime(\"%Y\") + \".csv\"\n",
    "print(fileName)\n",
    "\n",
    "dfFootTraffic = loadAndCountFootTrafficFile(fileName)\n",
    "print(dfFootTraffic.info())\n",
    "dfFootTraffic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e37254",
   "metadata": {},
   "outputs": [],
   "source": [
    "date1 = '1-Nov-13'\n",
    "date2 = \"23/5/21\"\n",
    "\n",
    "pattern = reutil.regex_DateDdMmmYy()\n",
    "if re.match(pattern, date1):\n",
    "    print(\"date1 regex_DateDdMmmYy MATCH\")\n",
    "else:\n",
    "    print(\"date1 regex_DateDdMmmYy NO MATCH\")\n",
    "\n",
    "\n",
    "pattern = reutil.regex_DateDdMmmYy()\n",
    "if re.match(pattern, date2):\n",
    "    print(\"date2 regex_DateDdMmmYy MATCH\")\n",
    "else:\n",
    "    print(\"date2 regex_DateDdMmmYy NO MATCH\")\n",
    "\n",
    "pattern = reutil.regex_DateDdMmYy()\n",
    "if re.match(pattern, date2):\n",
    "    print(\"date2 regex_DateDdMmmYy MATCH\")\n",
    "else:\n",
    "    print(\"date2 regex_DateDdMmmYy NO MATCH\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480df3ee",
   "metadata": {},
   "source": [
    "Find all streets that exist in all files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filesEndDate = datetime(2022, 7, 1)\n",
    "#filesStartDate = datetime(2022, 4, 1)\n",
    "filesStartDate = datetime(2013, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca59a172",
   "metadata": {},
   "outputs": [],
   "source": [
    "stepperDate = filesEndDate\n",
    "stepperDate = stepperDate - relativedelta(months=1)\n",
    "stepCount = 0\n",
    "\n",
    "columnList = []\n",
    "\n",
    "while stepperDate >= filesStartDate:\n",
    "    fileName = stepperDate.strftime(\"%B\") + \"_\" + stepperDate.strftime(\"%Y\") + \".csv\"\n",
    "\n",
    "    foot_traffic = pd.read_csv(footTrafficFolder + fileName)\n",
    "\n",
    "    if len(columnList) == 0:\n",
    "        columnList = foot_traffic.columns\n",
    "    else:\n",
    "        # filter the list to include only if exists in other list\n",
    "        # columnList = [x for x in columnList if x[0] in foot_traffic.columns]\n",
    "        columnList = list(filter(lambda x: x in foot_traffic.columns, columnList))\n",
    "\n",
    "    # step back\n",
    "    stepperDate = stepperDate - relativedelta(months=1)\n",
    "\n",
    "    # Sanity check, break in case of an infinite loop\n",
    "    stepCount += 1\n",
    "    if stepCount > 1000:\n",
    "        break\n",
    "\n",
    "print(columnList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527d280f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now go back to the month before\n",
    "stepperDate = filesEndDate\n",
    "stepperDate = stepperDate - relativedelta(months=1)\n",
    "stepCount = 0\n",
    "\n",
    "# For each month, load the data, append it to the total dataframe then step back another month\n",
    "# keep going until we get all the way to the start date\n",
    "while stepperDate >= filesStartDate:\n",
    "    fileName = stepperDate.strftime(\"%B\") + \"_\" + stepperDate.strftime(\"%Y\") + \".csv\"\n",
    "    # print(fileName)\n",
    "\n",
    "    dfMonth = loadAndCountFootTrafficFile(fileName)\n",
    "    dfFootTraffic = pd.concat([dfFootTraffic, dfMonth])\n",
    "\n",
    "    # step back\n",
    "    stepperDate = stepperDate - relativedelta(months=1)\n",
    "\n",
    "    # Sanity check, break in case of an infinite loop\n",
    "    stepCount += 1\n",
    "    if stepCount > 1000:\n",
    "        break\n",
    "\n",
    "\n",
    "# Order by the date desc\n",
    "dfFootTraffic = dfFootTraffic.sort_values([\"date\"], ascending=False)\n",
    "\n",
    "print(dfFootTraffic.info())\n",
    "dfFootTraffic.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ec4913",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFootTraffic.sort_values([\"date\"], ascending=True).head()\n",
    "\n",
    "dfFootTraffic.to_csv(tempFolder + \"foottrafficstreet.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d524b0e6",
   "metadata": {},
   "source": [
    "# Join and plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7ad877",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_temp['date'] = make_date_col(max_temp)\n",
    "min_temp['date'] = make_date_col(min_temp)\n",
    "solar_exp['date'] = make_date_col(solar_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4110e7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get out the range of dates that have been loaded from the foot traffic and filter the weather data accordingly\n",
    "ftMinDate = dfFootTraffic[\"date\"].min()\n",
    "ftMaxDate = dfFootTraffic[\"date\"].max()\n",
    "\n",
    "print(ftMinDate)\n",
    "print(ftMaxDate)\n",
    "\n",
    "max_temp=filter_weathers(max_temp, ftMinDate, ftMaxDate)\n",
    "min_temp=filter_weathers(min_temp, ftMinDate, ftMaxDate)\n",
    "solar_exp=filter_weathers(solar_exp, ftMinDate, ftMaxDate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0d8f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_temp.rename(columns={\"Maximum temperature (Degree C)\":\"max_temp\"},inplace=True)\n",
    "min_temp.rename(columns={\"Minimum temperature (Degree C)\":\"min_temp\"},inplace=True)\n",
    "solar_exp.rename(columns={\"Daily global solar exposure (MJ/m*m)\":\"solar_exp\"},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488c94ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(max_temp.info())\n",
    "max_temp.head()\n",
    "\n",
    "\n",
    "# max_temp.to_csv(tempFolder + \"maxtemp.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8796e1cc",
   "metadata": {},
   "source": [
    "Write out a datafile with the date and the total foot traffic numbers in Melbourne, for future use\n",
    "\n",
    "Also, create a datafile with the foot traffic and all the weather columns by day for Melbourne, we can use that later as a source datafile for basic modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cab1c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Foot Traffic by day Data\n",
    "outputFootTrafficFileName = \"FootTrafficMelbStreet_\" + filesStartDate.strftime(\"%Y%m%d\") + \"_\" + filesEndDate.strftime(\"%Y%m%d\") + \".csv\"\n",
    "dfFootTraffic.to_csv(\"./data_files/\" + outputFootTrafficFileName, index=False)\n",
    "\n",
    "print(dfFootTraffic.info())\n",
    "dfFootTraffic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbc5929",
   "metadata": {},
   "outputs": [],
   "source": [
    "rain.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f2a77e",
   "metadata": {},
   "source": [
    "The data we want is total rain, and also Quality, which is a Y/N and shows whether the rain measurement has passed full quality control. If N, then the measurement might be suspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbd7550",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfRainToMerge = rain[[\"total_rain\", \"Quality\", \"date\"]]\n",
    "dfRainToMerge.rename(columns={\"Quality\":\"rain_quality\"},inplace=True)\n",
    "\n",
    "dfFootTrafficWeather = pd.merge(dfFootTraffic, dfRainToMerge, how=\"inner\", on=\"date\")\n",
    "dfFootTrafficWeather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a965ed77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the Max Temp\n",
    "dfMaxTempToMerge = max_temp[[\"max_temp\", \"Quality\", \"date\"]]\n",
    "dfMaxTempToMerge.rename(columns={\"Quality\":\"max_temp_quality\"},inplace=True)\n",
    "dfFootTrafficWeather = pd.merge(dfFootTrafficWeather, dfMaxTempToMerge, how=\"inner\", on=\"date\")\n",
    "\n",
    "# Merge the Max Temp\n",
    "dfMinTempToMerge = min_temp[[\"min_temp\", \"Quality\", \"date\"]]\n",
    "dfMinTempToMerge.rename(columns={\"Quality\":\"min_temp_quality\"},inplace=True)\n",
    "dfFootTrafficWeather = pd.merge(dfFootTrafficWeather, dfMinTempToMerge, how=\"inner\", on=\"date\")\n",
    "\n",
    "dfFootTrafficWeather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b32f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "solar_exp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c06ee47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the Solar Exposure\n",
    "dfSolarExpToMerge = solar_exp[[\"solar_exp\", \"date\"]]\n",
    "dfFootTrafficWeather = pd.merge(dfFootTrafficWeather, dfSolarExpToMerge, how=\"inner\", on=\"date\")\n",
    "\n",
    "print(dfFootTrafficWeather.info())\n",
    "dfFootTrafficWeather.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0054935",
   "metadata": {},
   "source": [
    "Add the day of the week as a feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca66d03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFootTrafficWeather[\"WeekDay\"] = dfFootTrafficWeather.apply(lambda x: x[\"date\"].weekday(), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4491dde",
   "metadata": {},
   "source": [
    "Adding annual population and growth rating to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10288d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, create a temp dateyear column for joining\n",
    "dfFootTrafficWeather[\"date_year\"] = dfFootTrafficWeather.apply(lambda x: x[\"date\"].year, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3463903a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFootTrafficWeather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b3294e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the population file\n",
    "dfPop = pd.read_csv(\"./data_files/greatermelb_population_annual.csv\")\n",
    "print(dfPop.shape)\n",
    "print(dfPop.info())\n",
    "dfPop.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b61883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to just a date year column\n",
    "dfPop[\"date_year\"] = dfPop.apply(lambda x: pd.to_datetime(x[\"date\"]).year, axis=1)\n",
    "dfPop = dfPop.rename(columns={ \" Population\" : \"population_annual\", \" Annual Change\" : \"population_change_annual\" })\n",
    "del dfPop[\"date\"]\n",
    "dfPop.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29627e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFootTrafficWeather = pd.merge(dfFootTrafficWeather, dfPop, on=\"date_year\")\n",
    "del dfFootTrafficWeather[\"date_year\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060f0472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and join the Holidays file\n",
    "dfHol = pd.read_csv(\"./data_files/Holidays_20130101_20220701.csv\")\n",
    "dfHol[\"date\"] = pd.to_datetime(dfHol[\"date\"])\n",
    "dfFootTrafficWeather = pd.merge(dfFootTrafficWeather, dfHol, on=\"date\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802c3979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and join the Lockdown file\n",
    "dfLockdown = pd.read_csv(\"./data_files/Melb_Lockdown_Dates.csv\")\n",
    "dfLockdown[\"date\"] = pd.to_datetime(dfLockdown[\"date\"])\n",
    "dfFootTrafficWeather = pd.merge(dfFootTrafficWeather, dfLockdown, on=\"date\", how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4312c83a",
   "metadata": {},
   "source": [
    "Create a Date Year-Month key for joining monthly data files like retain and all ords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7175cf96",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFootTrafficWeather[\"date_ym\"] = dfFootTrafficWeather.apply(lambda x: str(pd.to_datetime(x[\"date\"]).year) + \"-\" + str(pd.to_datetime(x[\"date\"]).month), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e202d3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the Retail data and join it to our foot traffic data\n",
    "dfRetail = pd.read_csv(\"./data_files/OFFLINE_Retail_Turnover_VIC.csv\")\n",
    "\n",
    "dfRetail[\"date_ym\"] = dfRetail.apply(lambda x: str(pd.to_datetime(x[\"date\"]).year) + \"-\" + str(pd.to_datetime(x[\"date\"]).month), axis=1)\n",
    "dfRetail=dfRetail.rename(columns= {\"Original_Turnover\":\"OfflineRetail_Original_Turnover\", \"Seasonally_Adjusted_Turnover\":\"OfflineRetail_Seasonally_Adjusted_Turnover\",\"Trend_Turnover\":\"OfflineRetail_Trend_Turnover\"})\n",
    "del dfRetail[\"date\"]\n",
    "dfRetail.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c99a4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFootTrafficWeather = pd.merge(dfFootTrafficWeather, dfRetail, on=\"date_ym\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6586208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the All Ords data and join it to our foot traffic data\n",
    "dfAllOrds = pd.read_csv(\"./data_files_raw/aus-all-ords.csv\")\n",
    "\n",
    "#dfAllOrds[\"date_ym\"] = dfAllOrds[\"Year\"] + \"-\" + dfAllOrds[\"Month Num\"]\n",
    "dfAllOrds[\"date_ym\"] = dfAllOrds.apply(lambda x: str(x[\"Year\"]) + \"-\" + str(x[\"Month Num\"]), axis=1)\n",
    "del dfAllOrds[\"Year\"]\n",
    "del dfAllOrds[\"Month Name\"]\n",
    "del dfAllOrds[\"Month Num\"]\n",
    "dfAllOrds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8850dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFootTrafficWeather = pd.merge(dfFootTrafficWeather, dfAllOrds, on=\"date_ym\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcc0798",
   "metadata": {},
   "outputs": [],
   "source": [
    "del dfFootTrafficWeather[\"date_ym\"] \n",
    "print(dfFootTrafficWeather.info())\n",
    "dfFootTrafficWeather.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1f97d4",
   "metadata": {},
   "source": [
    "Detect any duplicate rows and remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a5ab3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfFootTrafficWeather.shape)\n",
    "dfFootTrafficWeather.groupby('date').filter(lambda group: len(group) > 1).groupby('date').size().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3087992",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFootTrafficWeather = dfFootTrafficWeather.drop_duplicates()\n",
    "print(dfFootTrafficWeather.shape)\n",
    "dfFootTrafficWeather.groupby('date').filter(lambda group: len(group) > 1).groupby('date').size().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc51fd2",
   "metadata": {},
   "source": [
    "Write out all the joined data to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74758efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputFootTrafficWeatherFileName = \"FT_Street_Melb_\" + filesStartDate.strftime(\"%Y%m%d\") + \"_\" + filesEndDate.strftime(\"%Y%m%d\") + \".csv\"\n",
    "dfFootTrafficWeather.to_csv(\"./data_files/\" + outputFootTrafficWeatherFileName, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "dcbc78149e46ccbab92a3f68a48c52feb0796c7e10dad8e3f1a2a5a780973376"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
